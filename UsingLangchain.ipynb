{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30683,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-18T04:02:42.511499Z",
          "iopub.execute_input": "2024-04-18T04:02:42.512413Z",
          "iopub.status.idle": "2024-04-18T04:02:55.412888Z",
          "shell.execute_reply.started": "2024-04-18T04:02:42.512377Z",
          "shell.execute_reply": "2024-04-18T04:02:55.411665Z"
        },
        "trusted": true,
        "id": "DBkpBHiZs175",
        "outputId": "b9c81dd3-4e45-496e-9b12-019b87d8ae61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
            "  Downloading langchain_core-0.1.44-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.48-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.33 langchain-core-0.1.44 langchain-text-splitters-0.0.1 langsmith-0.1.48 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.1 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY = getpass('Enter the secret value: ')\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:04:09.297707Z",
          "iopub.execute_input": "2024-04-18T04:04:09.2986Z",
          "iopub.status.idle": "2024-04-18T04:04:18.826174Z",
          "shell.execute_reply.started": "2024-04-18T04:04:09.298566Z",
          "shell.execute_reply": "2024-04-18T04:04:18.825443Z"
        },
        "trusted": true,
        "id": "K-Lmu8zBs177",
        "outputId": "d0a1b01a-d637-4bdc-e02c-95618a1c3fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the secret value: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Template"
      ],
      "metadata": {
        "id": "-Vp6_9dVs177"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:06:15.208371Z",
          "iopub.execute_input": "2024-04-18T04:06:15.209038Z",
          "iopub.status.idle": "2024-04-18T04:06:15.213273Z",
          "shell.execute_reply.started": "2024-04-18T04:06:15.209009Z",
          "shell.execute_reply": "2024-04-18T04:06:15.212088Z"
        },
        "trusted": true,
        "id": "2vNV3Jjrs178"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template('Describe un objeto que te resulte {adjetivo} y por qué tiene ese efecto en ti')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:06:16.880336Z",
          "iopub.execute_input": "2024-04-18T04:06:16.880724Z",
          "iopub.status.idle": "2024-04-18T04:06:16.885526Z",
          "shell.execute_reply.started": "2024-04-18T04:06:16.880695Z",
          "shell.execute_reply": "2024-04-18T04:06:16.884405Z"
        },
        "trusted": true,
        "id": "F8cC7lMys178"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.format(adjetivo='fascinante')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:06:53.402397Z",
          "iopub.execute_input": "2024-04-18T04:06:53.403263Z",
          "iopub.status.idle": "2024-04-18T04:06:53.410398Z",
          "shell.execute_reply.started": "2024-04-18T04:06:53.403233Z",
          "shell.execute_reply": "2024-04-18T04:06:53.409464Z"
        },
        "trusted": true,
        "id": "D_9TJMJls178",
        "outputId": "920610f5-26ed-49e2-9415-b651c8fcbc02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Describe un objeto que te resulte fascinante y por qué tiene ese efecto en ti'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chains with Prompt Template"
      ],
      "metadata": {
        "id": "Blf02JPXs179"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = 'Eres un asistente útil que traduce del {idioma_entrada} al {idioma_salida} el texto: {texto}.'\n",
        "template"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:08:33.202294Z",
          "iopub.execute_input": "2024-04-18T04:08:33.202644Z",
          "iopub.status.idle": "2024-04-18T04:08:33.208546Z",
          "shell.execute_reply.started": "2024-04-18T04:08:33.202616Z",
          "shell.execute_reply": "2024-04-18T04:08:33.207681Z"
        },
        "trusted": true,
        "id": "sSQg7Lsjs179",
        "outputId": "9cfae434-dcc9-4c22-dbe4-22ab7f78c698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Eres un asistente útil que traduce del {idioma_entrada} al {idioma_salida} el texto: {texto}.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = 'Me encanta programar'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:08:40.771908Z",
          "iopub.execute_input": "2024-04-18T04:08:40.772681Z",
          "iopub.status.idle": "2024-04-18T04:08:40.776685Z",
          "shell.execute_reply.started": "2024-04-18T04:08:40.772649Z",
          "shell.execute_reply": "2024-04-18T04:08:40.775667Z"
        },
        "trusted": true,
        "id": "xvduzrz3s179"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=['idioma_entrada', 'idioma_salida', 'texto'], template=template\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:10:44.488914Z",
          "iopub.execute_input": "2024-04-18T04:10:44.489791Z",
          "iopub.status.idle": "2024-04-18T04:10:44.494228Z",
          "shell.execute_reply.started": "2024-04-18T04:10:44.489742Z",
          "shell.execute_reply": "2024-04-18T04:10:44.493233Z"
        },
        "trusted": true,
        "id": "se3xovpss17-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:11:25.12252Z",
          "iopub.execute_input": "2024-04-18T04:11:25.123446Z",
          "iopub.status.idle": "2024-04-18T04:11:39.538637Z",
          "shell.execute_reply.started": "2024-04-18T04:11:25.123413Z",
          "shell.execute_reply": "2024-04-18T04:11:39.537528Z"
        },
        "trusted": true,
        "id": "kQNmhIUas17-",
        "outputId": "83def0d9-616d-4f2a-c36e-dc935568ea4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.1.44)\n",
            "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai)\n",
            "  Downloading openai-1.21.2-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.9/309.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain-openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (0.1.48)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.6.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain-openai) (3.10.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (2.0.7)\n",
            "Installing collected packages: h11, tiktoken, httpcore, httpx, openai, langchain-openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain-openai-0.1.3 openai-1.21.2 tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:12:01.112982Z",
          "iopub.execute_input": "2024-04-18T04:12:01.113378Z",
          "iopub.status.idle": "2024-04-18T04:12:01.920876Z",
          "shell.execute_reply.started": "2024-04-18T04:12:01.113346Z",
          "shell.execute_reply": "2024-04-18T04:12:01.920111Z"
        },
        "trusted": true,
        "id": "NPZo9553s17-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:12:29.698009Z",
          "iopub.execute_input": "2024-04-18T04:12:29.69856Z",
          "iopub.status.idle": "2024-04-18T04:12:29.734566Z",
          "shell.execute_reply.started": "2024-04-18T04:12:29.698524Z",
          "shell.execute_reply": "2024-04-18T04:12:29.733805Z"
        },
        "trusted": true,
        "id": "Q9xQ9eKPs17-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:12:49.233546Z",
          "iopub.execute_input": "2024-04-18T04:12:49.234249Z",
          "iopub.status.idle": "2024-04-18T04:12:49.239233Z",
          "shell.execute_reply.started": "2024-04-18T04:12:49.234217Z",
          "shell.execute_reply": "2024-04-18T04:12:49.238183Z"
        },
        "trusted": true,
        "id": "VE5kS_D6s17-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto = 'Quiero aprender a bailar salsa'\n",
        "res = chain.invoke(input={'idioma_entrada':'español', 'idioma_salida': 'inglés', 'texto': texto})\n",
        "print(res)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:16:28.700225Z",
          "iopub.execute_input": "2024-04-18T04:16:28.70096Z",
          "iopub.status.idle": "2024-04-18T04:16:29.466466Z",
          "shell.execute_reply.started": "2024-04-18T04:16:28.700911Z",
          "shell.execute_reply": "2024-04-18T04:16:29.465536Z"
        },
        "trusted": true,
        "id": "f-cFGnRPs17-",
        "outputId": "c690f432-cc34-45cc-cf6b-277be7166486",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'idioma_entrada': 'español', 'idioma_salida': 'inglés', 'texto': 'Quiero aprender a bailar salsa', 'text': 'I want to learn how to dance salsa.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Movie Info"
      ],
      "metadata": {
        "id": "aBrQLF3As17-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:17:55.295976Z",
          "iopub.execute_input": "2024-04-18T04:17:55.296675Z",
          "iopub.status.idle": "2024-04-18T04:18:08.063824Z",
          "shell.execute_reply.started": "2024-04-18T04:17:55.296646Z",
          "shell.execute_reply": "2024-04-18T04:18:08.062629Z"
        },
        "trusted": true,
        "id": "H1mpP_u3s17-",
        "outputId": "b5543ac4-fa56-4aa9-ee11-16ad56b76afa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T04:19:37.219828Z",
          "iopub.execute_input": "2024-04-18T04:19:37.220486Z",
          "iopub.status.idle": "2024-04-18T04:19:37.225066Z",
          "shell.execute_reply.started": "2024-04-18T04:19:37.220455Z",
          "shell.execute_reply": "2024-04-18T04:19:37.224095Z"
        },
        "trusted": true,
        "id": "Oq_UZ_oss17-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def movies(movie):\n",
        "    url = f\"https://api.themoviedb.org/3/search/movie?query={movie}&include_adult=false&language=en-US&page=1\"\n",
        "\n",
        "    headers = {\n",
        "        \"accept\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI4NTM1NGY0MDRjM2U0NzRkY2U3NWNkZWMzZTIwZTkwMiIsInN1YiI6IjY2MjA5Zjk0ZTRjOWViMDE3Y2Y1NDVjOSIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.orMn-MR7g-qFGakhvGvx05989NpHQ8pnap9KCZ2r8JU\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "    return response"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T05:31:04.923888Z",
          "iopub.execute_input": "2024-04-18T05:31:04.924255Z",
          "iopub.status.idle": "2024-04-18T05:31:04.929782Z",
          "shell.execute_reply.started": "2024-04-18T05:31:04.924227Z",
          "shell.execute_reply": "2024-04-18T05:31:04.928647Z"
        },
        "trusted": true,
        "id": "adIk3yhUs17_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Te voy a dar información sobre algunas películas, me tienes que dar la información (en español)\n",
        "del título, fecha de estreno y resumen de las primeras 3 que aparezcan de forma  estructurada (si aparecen menos, me das las que aparezcan).\n",
        "{respuesta}\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=['respuesta'],\n",
        "    template=template\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T05:31:05.080905Z",
          "iopub.execute_input": "2024-04-18T05:31:05.081207Z",
          "iopub.status.idle": "2024-04-18T05:31:05.085907Z",
          "shell.execute_reply.started": "2024-04-18T05:31:05.081183Z",
          "shell.execute_reply": "2024-04-18T05:31:05.084969Z"
        },
        "trusted": true,
        "id": "dFHNGpHls17_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "response = movies('titanic')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T05:31:17.665634Z",
          "iopub.execute_input": "2024-04-18T05:31:17.666514Z",
          "iopub.status.idle": "2024-04-18T05:31:17.742864Z",
          "shell.execute_reply.started": "2024-04-18T05:31:17.666486Z",
          "shell.execute_reply": "2024-04-18T05:31:17.742111Z"
        },
        "trusted": true,
        "id": "L5RvbPc4s17_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(respuesta=response.text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-18T05:33:59.907297Z",
          "iopub.execute_input": "2024-04-18T05:33:59.907691Z",
          "iopub.status.idle": "2024-04-18T05:34:05.848599Z",
          "shell.execute_reply.started": "2024-04-18T05:33:59.907662Z",
          "shell.execute_reply": "2024-04-18T05:34:05.847647Z"
        },
        "trusted": true,
        "id": "oKhssGT0s17_",
        "outputId": "79545fca-6109-4ef5-a3c9-e89d4c289786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. **Titanic**\\n   - **Fecha de estreno:** 1997-11-18\\n   - **Resumen:** Rose DeWitt Bukater, de 101 años, cuenta la historia de su vida a bordo del Titanic, 84 años después. Una joven Rose aborda el barco con su madre y su prometido. Mientras tanto, Jack Dawson y Fabrizio De Rossi ganan boletos de tercera clase a bordo del barco. Rose cuenta toda la historia desde la partida del Titanic hasta su muerte en su primer y último viaje el 15 de abril de 1912.\\n\\n2. **Titanic**\\n   - **Fecha de estreno:** 1953-04-11\\n   - **Resumen:** Julia Sturges, infelizmente casada, decide ir a América con sus dos hijos en el Titanic. Su esposo, Richard, también arregla el pasaje en el lujoso transatlántico para tener la custodia de sus dos hijos. Todo esto pierde importancia una vez que el barco choca con un iceberg.\\n\\n3. **Titanic**\\n   - **Fecha de estreno:** 1943-11-10\\n   - **Resumen:** Esta película alemana poco conocida cuenta la verdadera historia del transatlántico británico que tuvo un destino trágico. Ernst Fritz Fürbringer interpreta al presidente de la White Star Line, quien presionó imprudentemente al capitán del Titanic para que hiciera el cruce más rápido posible a Nueva York.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cadenas Simples"
      ],
      "metadata": {
        "id": "5_EiAUU4xrIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = ChatOpenAI()"
      ],
      "metadata": {
        "id": "0-kmwA-Zs17_",
        "outputId": "f678c3d5-3c0c-4972-9bc2-75131a346e16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_openai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fa112cb85101>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Eres un detective experimentado. Describe las pistas clave que condujeron a resolver el caso de\n",
        " {caso} en {ciudad}.\"\"\""
      ],
      "metadata": {
        "id": "mjGoqPz0x8Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template(template=template)"
      ],
      "metadata": {
        "id": "Mu8k-rGZyLbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt_template,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "GFrSHT2vyTyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = chain.invoke({'caso': 'Desaparición', 'ciudad': 'Londres'})\n",
        "output['text']"
      ],
      "metadata": {
        "id": "04aA0o-g3ERj",
        "outputId": "20323bdf-c0c7-4929-9df3-9d8fc4f4f746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mEres un detective experimentado. Describe las pistas clave que condujeron a resolver el caso de\n",
            " Desaparición en Londres.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. Testimonios de testigos presenciales que vieron a la persona desaparecida por última vez en un lugar específico en Londres.\\n2. Registro de cámaras de seguridad que mostraban los movimientos de la persona desaparecida antes de su desaparición.\\n3. Análisis de su historial telefónico y de redes sociales para determinar con quién había estado en contacto recientemente.\\n4. Investigación de posibles motivos detrás de su desaparición, como problemas personales o conflictos con otras personas.\\n5. Búsqueda de posibles lugares donde la persona desaparecida podría estar escondida o retenida contra su voluntad.\\n6. Colaboración con otras agencias de aplicación de la ley y seguimiento de pistas adicionales que surgieron durante la investigación. \\n7. Utilización de tecnología forense para analizar pruebas físicas encontradas en la escena de la desaparición o en lugares relacionados con el caso.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequential Chains"
      ],
      "metadata": {
        "id": "4bMBGf-13mbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain"
      ],
      "metadata": {
        "id": "Mwq-Ni8y3Rif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm1 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
        "\n",
        "prompt_template1 = PromptTemplate.from_template(\n",
        "    template='Eres un cíentifico experimentado y programador en Python. Escribe una función que implemenete el concepto de {concepto}.'\n",
        ")\n",
        "\n",
        "chain1 = LLMChain(llm=llm1, prompt=prompt_template1)\n"
      ],
      "metadata": {
        "id": "mNGMEud23cv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm2 = ChatOpenAI(model_name='gpt-4-turbo-preview', temperature=1.2)\n",
        "\n",
        "prompt_template2 = PromptTemplate.from_template(\n",
        "    template='Dada la función de Python {funcion}, describela lo más detalladamente posible.'\n",
        ")\n",
        "\n",
        "\n",
        "chain2 = LLMChain(llm=llm2, prompt=prompt_template2)\n"
      ],
      "metadata": {
        "id": "TIkYAX9K4Tva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)"
      ],
      "metadata": {
        "id": "R55xzo9-40Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = overall_chain.invoke('obtener los primeros \"n\" números primos')\n"
      ],
      "metadata": {
        "id": "wGMt_rdt5JAJ",
        "outputId": "2a334483-ad72-4666-d1d4-99ec1a361ba8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mAquí tienes una función en Python que devuelve los primeros \"n\" números primos:\n",
            "\n",
            "```python\n",
            "def es_primo(num):\n",
            "    if num < 2:\n",
            "        return False\n",
            "    for i in range(2, int(num ** 0.5) + 1):\n",
            "        if num % i == 0:\n",
            "            return False\n",
            "    return True\n",
            "\n",
            "def primeros_primos(n):\n",
            "    primos = []\n",
            "    num = 2\n",
            "    while len(primos) < n:\n",
            "        if es_primo(num):\n",
            "            primos.append(num)\n",
            "        num += 1\n",
            "    return primos\n",
            "\n",
            "n = 10\n",
            "print(f\"Los primeros {n} números primos son: {primeros_primos(n)}\")\n",
            "```\n",
            "\n",
            "Esta función primero verifica si un número es primo utilizando la función `es_primo`, que comprueba si un número es divisible por algún número menor que su raíz cuadrada. Luego, la función `primeros_primos` genera los primeros \"n\" números primos y los devuelve en una lista. Finalmente, se imprime la lista de los primeros \"n\" números primos. Puedes cambiar el valor de `n` para obtener más o menos números primos.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mEsta implementación de Python consiste en dos partes principales: la función `es_primo(num)` y la función `primeros_primos(n)`. Veamos en detalle cada parte para entender cómo se encuentran los primeros \"n\" números primos:\n",
            "\n",
            "### 1. Función `es_primo(num)`\n",
            "\n",
            "El objetivo de esta función es determinar si un número dado `num` es primo. Un número primo es aquel que solo es divisible entre sí mismo y el 1. La implementación sigue estos pasos:\n",
            "\n",
            "- Primero, comprueba si `num` es menor que 2, retornando `False` de ser así, ya que los números menores que 2 no son considerados primos.\n",
            "- Luego, ejecuta un bucle `for` que va desde 2 hasta la raíz cuadrada de `num` (por esto se usa `int(num ** 0.5) + 1` para asegurar que se cubren todos los posibles divisores hasta este punto). La idea de ir solo hasta la raíz cuadrada es una optimización que permite reducir el número de comprobaciones necesarias para afirmar si un número es primo o no, usando un principio matemático que indica que si un número no tiene divisores menores o iguales a su raíz cuadrada, entonces no los tendrá mayores a eso y por ende, es primo.\n",
            "- Si, durante el bucle, se encuentra algún número que divide exactamente a `num` (es decir, el resto de la división `%` es 0), se retorna `False`, confirmando así que el número no es primo.\n",
            "- Si se completa el bucle sin encontrar ningun divisor, se retorna `True`, confirmando que el número es primo.\n",
            "\n",
            "### 2. Función `primeros_primos(n)`\n",
            "\n",
            "Esta función genera una lista de los primeros \"n\" números primos:\n",
            "\n",
            "- Inicia una lista vacía `primos` para almacenar los números primos encontrados.\n",
            "- Define un contador `num` que inicia en 2, ya que 2 es el primer número primo.\n",
            "- Usa un bucle `while` que continúa hasta que la longitud de la lista `primos` sea igual a \"n\" (esto garantiza que solo se encuentren y guarden los primeros \"n\" números primos).\n",
            "- Dentro del loop, utiliza la función `es_primo(num)` para verificar si el número actual `num` es primo. Si es primo, lo agrega a la lista `primos`.\n",
            "- Independientemente de si el número es primo o no, incrementa `num` en 1 para continuar la búsqueda con el siguiente número.\n",
            "- Finalmente, una vez que la lista contiene \"n\" números primos, la función retorna la lista `primos`.\n",
            "\n",
            "### Ejemplo de Uso:\n",
            "\n",
            "Para usar estas funciones y por ejemplo, encontrar los primeros 10 números primos, se asigna el valor 10 a la variable `n` y se llama a la función `primeros_primos(n)`. La lista de los primeros 10 números primos se imprimirá gracias a la última línea de código.\n",
            "\n",
            "Esta implementación es un buen ejemplo de cómo combinar principios matemáticos con técnicas de programación eficientes para resolver un problema, en este caso, encontrar números primos.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ReAct Agent(RAG)"
      ],
      "metadata": {
        "id": "vdeb4XTQ6Dne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-openai -q"
      ],
      "metadata": {
        "id": "h7ZhjJp56TCF",
        "outputId": "7e6d6c5c-e899-43e0-fd8c-8467f0ecc026",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.0/311.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "\n",
        "output = llm.invoke('Explica el procesamiento de lenguaje natural en una oración', model='gpt-3.5-turbo', temperature=0.1)\n",
        "print(output.content)"
      ],
      "metadata": {
        "id": "8p1KZYHm5el6",
        "outputId": "e728a81a-44c7-4044-df7c-ab8dd012415c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El procesamiento de lenguaje natural es una rama de la inteligencia artificial que se encarga de analizar y comprender el lenguaje humano de manera automatizada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import (\n",
        "    SystemMessage,\n",
        "    AIMessage,\n",
        "    HumanMessage\n",
        ")"
      ],
      "metadata": {
        "id": "Ee0pB1FO6LLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content='Eres un chef y respondes solo con conceptos culinarios'),\n",
        "    HumanMessage(content='Explica procesamiento del lenguaje natural en una oración')\n",
        "]"
      ],
      "metadata": {
        "id": "MU8dAHS4_HyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.invoke(messages, model='gpt-3.5-turbo', temperature=0.1)\n",
        "print(output.content)"
      ],
      "metadata": {
        "id": "liOU7pcU_YYw",
        "outputId": "04e69cb4-bc96-4e2b-d5de-185acd8db0fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El procesamiento del lenguaje natural es como seguir una receta para entender y analizar el lenguaje humano de manera automatizada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agents in Action"
      ],
      "metadata": {
        "id": "XV84WYdB_jwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_experimental -q"
      ],
      "metadata": {
        "id": "eRF69WZA_dE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.utilities import PythonREPL\n",
        "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
        "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model='gpt-4-turbo-preview', temperature=0)\n",
        "\n",
        "agent_executor = create_python_agent(\n",
        "    llm=llm,\n",
        "    tool=PythonREPLTool(),\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "8g4-IohH_pRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Encuentra el promedio de los cubos de los números del 1 al 10 y fuerza a que se vean 3 decimales'\n",
        "response = agent_executor.invoke(prompt)"
      ],
      "metadata": {
        "id": "ddKID_LYBoCU",
        "outputId": "f24b4b76-96f4-4ba6-83a6-1d3bf8f5059b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mPrimero, necesito calcular los cubos de los números del 1 al 10. Luego, calcularé el promedio de esos cubos. Finalmente, formatearé el resultado para que muestre exactamente 3 decimales.\n",
            "Action: Python_REPL\n",
            "Action Input: print(sum([i**3 for i in range(1, 11)]) / 10)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m302.5\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mAhora necesito formatear el resultado para que muestre exactamente 3 decimales.\n",
            "Action: Python_REPL\n",
            "Action Input: print(\"{:.3f}\".format(sum([i**3 for i in range(1, 11)]) / 10))\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m302.500\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 302.500\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['input'])\n",
        "print(response['output'])"
      ],
      "metadata": {
        "id": "4f-N0VWvCLdZ",
        "outputId": "a2e7821e-8b7a-41c2-b38f-1cce8511eba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encuentra el promedio de los cubos de los números del 1 al 10 y fuerza a que se vean 3 decimales\n",
            "302.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangChain Tools: DuckDuckGo & Wikipedia"
      ],
      "metadata": {
        "id": "rna-iqLeEGhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install duckduckgo-search -q"
      ],
      "metadata": {
        "id": "0siAm-zDETpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "output = search.run('¿Cual es el principal ingrediente de la pizza Margarita?')\n",
        "print(output)"
      ],
      "metadata": {
        "id": "vD_M4e3FD8Qu",
        "outputId": "5f6d4903-ab8d-4451-c7ae-032fd5d345d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Siete empresas con la pujanza del Valle del Cauca aceptaron el desafío de exportar a Emiratos Árabes. Según la Cámara de Comercio de Cali, se seleccionaron 16 países que cumplen las ... El municipio de Cartago, conocido como la «capital mundial del Bordado», se encuentra en vísperas de las elecciones locales, y los cartagueños están a punto de decidir quién será su próximo alcalde.Las elecciones locales y regionales se llevará a cabo el próximo 29 de octubre. La elección del nuevo alcalde es un asunto de gran relevancia para los habitantes de este municipio que ... Una de las principales características de la nueva administración municipal de Cartago es que no ha tenido retraso en sus servicios básicos de asistencia a la ciudadanía. Este proceso de cambio, ha sido armónico, tranquilo y sin mayores inconvenientes. En aras de continuar los procesos públicos y no perjudicar en ningún sentido el ... 12 de los 17 escaños disponibles en el Concejo Municipal de Cartago, serán ocupados por nuevos concejales. Este cambio notable denota un fuerte deseo de cambio para un mejor control político y a su vez un mayor acercamiento a las necesidades y perspectivas de la comunidad. Este nuevo liderazgo se enfrentará a los desafíos y oportunidades ... La Nota Económica. En los últimos 13 años, la inversión extranjera en el Valle ha representado 2.300 millones de dólares, generando 21.000 empleos directos en toda la región. La historia del desarrollo productivo del Valle del Cauca es un referente para el país. La región aporta el 10% del PIB nacional, representando el 9% de la ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
        "\n",
        "wrapper = DuckDuckGoSearchAPIWrapper(region='cl-es', max_results=3, safesearch='moderate')\n",
        "search = DuckDuckGoSearchRun(api_wrapper=wrapper, source='news')\n",
        "output = search.run('nvidia')"
      ],
      "metadata": {
        "id": "TdRlqjQ3Euvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "0a3XR1p9IeAs",
        "outputId": "3627076d-5ef0-4b2d-f789-ce4564bd9557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"NVIDIA announces the GeForce RTX 40 SUPER Series family of GPUs, powered by Ada Lovelace architecture and AI, for gaming and creating. The series includes the RTX 4080 SUPER, RTX 4070 Ti SUPER and RTX 4070 SUPER, starting from $599. On June 29th, the GeForce RTX 4060 will go on sale, with prices starting at $299. For gamers playing on previous-gen GPUs, the NVIDIA Ada Lovelace architecture at the heart of the GeForce RTX 4060 delivers a massive upgrade, multiplying your performance, and supercharging creative apps. And thanks to the Ada architecture's industry-leading ... NVIDIA recommends that you check with your notebook OEM for recommended software updates for your notebook. Game Ready for Diablo IV This new Game Ready Driver provides the best gaming experience for the latest new games featuring DLSS 3 technology including Diablo IV. Additionally, this Game Ready Driver supports the launch of titles ...\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'snippet: (.*?), title: (.*?), link: (.*?)\\],'\n",
        "matches = re.findall(pattern, output, re.DOTALL)\n",
        "\n",
        "for snippet, title, link in matches:\n",
        "  print(f'Snippet: {snippet}\\nTitle: {title}\\nLink: {link}\\n')\n",
        "  print('-' * 50)"
      ],
      "metadata": {
        "id": "IQ75ED03GHK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wikipedia"
      ],
      "metadata": {
        "id": "iDVHXLB_Ih9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia -q"
      ],
      "metadata": {
        "id": "0QqgoTrpGIT3",
        "outputId": "f415a3dd-39c4-485c-98ca-cd3614489902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "api_wrapper = WikipediaAPIWrapper(lang='es', top_k_results=1, doc_content_chars_max=10000)\n",
        "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
        "wiki.invoke({'query': 'Sora de OpenAI'})"
      ],
      "metadata": {
        "id": "NNkYslYDIkbV",
        "outputId": "9fc4060d-3ad0-4910-8eef-5e4b664ff2b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: OpenAI\\nSummary: OpenAI es una empresa de investigación y despliegue de inteligencia artificial que declara tener como misión asegurar que la inteligencia artificial general beneficie a toda la humanidad.[4]\\u200b\\nAlgunas de sus áreas de enfoque son los modelos generativos, la seguridad, la robótica y el lenguaje natural. OpenAI también ofrece una plataforma de API que permite a los usuarios acceder y construir sus propios modelos de IA personalizados.\\nOpenAI fue fundada en 2015 por Ilya Sutskever, Greg Brockman, Trevor Blackwell, Andrej Karpathy y con Sam Altman y Elon Musk como miembros iniciales de la junta.[5]\\u200b[6]\\u200b Se fundó principalmente como una organización sin fines de lucro, pero en 2019 se convirtió en una empresa híbrida, con una entidad sin fines de lucro y otra con fines de lucro.\\nAlgunos de sus proyectos más destacados son ChatGPT, un chatbot (Modelo de lenguaje) que puede ver, oír y hablar[7]\\u200b; DALL·E 3, un modelo de imágenes que puede crear imágenes a partir de descripciones de texto[8]\\u200b; y GPT-4, su modelo de lenguaje más avanzado y capaz.[9]\\u200b\\nMicrosoft proporcionó a OpenAI una inversión de mil millones de dólares en 2019 y una inversión de diez mil millones de dólares en 2023.[10]\\u200b[11]\\u200b Los sistemas de OpenAI se ejecutan en una plataforma de supercomputación basada en Azure de Microsoft.[12]\\u200b[13]\\u200b[14]\\u200b\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create ReAct Agent"
      ],
      "metadata": {
        "id": "XVxtB9RzJK3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchainhub langchain_experimental wikipedia duckduckgo-search -q"
      ],
      "metadata": {
        "id": "8f_0BM0wI8h7",
        "outputId": "a4aaf21c-2d1f-4092-e276-47daa4533136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import hub\n",
        "from langchain.agents import Tool, AgentExecutor, initialize_agent, create_react_agent\n",
        "from langchain.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
        "from langchain.utilities import WikipediaAPIWrapper\n",
        "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "oEtleyapJQTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY = getpass('Enter the secret value: ')\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "LTFsiAbO6FdG",
        "outputId": "d2e090f3-fe0b-4db6-f8c1-ae0064c59dea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the secret value: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name='gpt-4-turbo-preview', temperature=0)"
      ],
      "metadata": {
        "id": "XprO0NMh50Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = '''\n",
        "Responde las siguientes preguntas en italiano lo mejor que puedas.\n",
        "Preguntas: {q}\n",
        "'''"
      ],
      "metadata": {
        "id": "oiAwoYP05D9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template(template)\n",
        "prompt = hub.pull('hwchase17/react')"
      ],
      "metadata": {
        "id": "iVv-kpRK7J3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Python REPL Tool\n",
        "python_repl = PythonREPLTool()\n",
        "python_repl_tool = Tool(\n",
        "    name='Python REPL',\n",
        "    func=python_repl.run,\n",
        "    description='Útil cuando necesitar usar Python para responder una pregunta. Debes ingresar código Python.'\n",
        ")"
      ],
      "metadata": {
        "id": "YcjgGy5X7f1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wikipedia Tool\n",
        "api_wrapper = WikipediaAPIWrapper()\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
        "wikipedia_tool = Tool(\n",
        "    name='Wikipedia',\n",
        "    func=wikipedia.run,\n",
        "    description='Útil cuando necesitas buscar un tema, país o persona en Wikipedia.'\n",
        ")"
      ],
      "metadata": {
        "id": "Zfp0CbsyCMHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DuckDuckGo Search Tool\n",
        "search = DuckDuckGoSearchRun()\n",
        "duckduckgo_tool = Tool(\n",
        "    name='DuckDuckGo Search',\n",
        "    func=search.run,\n",
        "    description='Útil cuando necesitas realizar una búsqueda en internet para encontrar información que otra herramienta no puede proporcionar.'\n",
        ")"
      ],
      "metadata": {
        "id": "NjkOnV1xCopG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [python_repl_tool, wikipedia_tool, duckduckgo_tool]\n",
        "agent = create_react_agent(llm, tools, prompt)"
      ],
      "metadata": {
        "id": "mZEW130mD2to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " agent_executor = AgentExecutor(\n",
        "     agent=agent,\n",
        "     tools=tools,\n",
        "     verbose=True,\n",
        "     handle_parsing_errors=True,\n",
        "     max_iterations=10\n",
        " )"
      ],
      "metadata": {
        "id": "-F-PgH5mHXQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'Cuéntame sobre la vida temprana de Lionel Messi'\n",
        "output = agent_executor.invoke({\n",
        "    'input':prompt_template.format(q=question)\n",
        "})"
      ],
      "metadata": {
        "id": "XHsTg0UIHrMi",
        "outputId": "b463c38b-e117-4428-d489-143de9a43b39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mNecesito buscar información sobre Lionel Messi en Wikipedia para responder la pregunta en italiano.\n",
            "Action: Wikipedia\n",
            "Action Input: Lionel Messi\u001b[0m\u001b[33;1m\u001b[1;3mPage: Lionel Messi\n",
            "Summary: Lionel Andrés \"Leo\" Messi (Spanish pronunciation: [ljoˈnel anˈdɾes ˈmesi] ; born 24 June 1987) is an Argentine professional footballer who plays as a forward for and captains both Major League Soccer club Inter Miami and the Argentina national team. Widely regarded as one of the greatest players of all time, Messi has won a record eight Ballon d'Or awards, a record six European Golden Shoes, and was named the world's best player for a record eight times by FIFA. Until leaving the club in 2021, he had spent his entire professional career with Barcelona, where he won a club-record 34 trophies, including ten La Liga titles, seven Copa del Rey titles, and the UEFA Champions League four times. With his country, he won the 2021 Copa América and the 2022 FIFA World Cup. A prolific goalscorer and creative playmaker, Messi holds the records for most goals in La Liga (474), most hat-tricks in La Liga (36) and the UEFA Champions League (eight), and most assists in La Liga (192) and the Copa América (17). He also has the most international goals by a South American male (106). Messi has scored over 800 senior career goals for club and country, and has the most goals by a player for a single club (672).\n",
            "Messi relocated to Spain from Argentina aged 13 to join Barcelona, for whom he made his competitive debut aged 17 in October 2004. He established himself as an integral player for the club within the next three years, and in his first uninterrupted season in 2008–09 he helped Barcelona achieve the first treble in Spanish football; that year, aged 22, Messi won his first Ballon d'Or. Three successful seasons followed, with Messi winning four consecutive Ballons d'Or, making him the first player to win the award four times. During the 2011–12 season, he set the La Liga and European records for most goals scored in a single season, while establishing himself as Barcelona's all-time top scorer. The following two seasons, Messi finished second for the Ballon d'Or behind Cristiano Ronaldo (his perceived career rival), before regaining his best form during the 2014–15 campaign, becoming the all-time top scorer in La Liga and leading Barcelona to a historic second treble, after which he was awarded a fifth Ballon d'Or in 2015. Messi assumed captaincy of Barcelona in 2018, and won a record sixth Ballon d'Or in 2019. Out of contract, he signed for French club Paris Saint-Germain in August 2021, spending two seasons at the club and winning Ligue 1 twice. Messi joined American club Inter Miami in July 2023, winning the Leagues Cup in August of that year.\n",
            "An Argentine international, Messi is the country's all-time leading goalscorer and also holds the national record for appearances. At youth level, he won the 2005 FIFA World Youth Championship, finishing the tournament with both the Golden Ball and Golden Shoe, and an Olympic gold medal at the 2008 Summer Olympics. His style of play as a diminutive, left-footed dribbler drew comparisons with his compatriot Diego Maradona, who described Messi as his successor. After his senior debut in August 2005, Messi became the youngest Argentine to play and score in a FIFA World Cup (2006), and reached the final of the 2007 Copa América, where he was named young player of the tournament. As the squad's captain from August 2011, he led Argentina to three consecutive finals: the 2014 FIFA World Cup, for which he won the Golden Ball, the 2015 Copa América, winning the Golden Ball, and the 2016 Copa América. After announcing his international retirement in 2016, he reversed his decision and led his country to qualification for the 2018 FIFA World Cup, a third-place finish at the 2019 Copa América, and victory in the 2021 Copa América, while winning the Golden Ball and Golden Boot for the latter. That same year, Messi received a seventh Ballon d'Or. In 2022, he led Argentina to win the 2022 FIFA World Cup, where he won a record second Golden Ball, scored seven goals including two in the final\u001b[0m\u001b[32;1m\u001b[1;3mAhora que tengo toda la información sobre la vida temprana de Lionel Messi, puedo responder la pregunta en italiano.\n",
            "Final Answer: Lionel Messi è nato il 24 giugno 1987 in Argentina. Messi si è trasferito in Spagna all'età di 13 anni per unirsi al Barcelona. Ha debuttato con il Barcelona all'età di 17 anni nel 2004 e ha avuto una carriera straordinaria sia con il club che con la nazionale argentina.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output['output']"
      ],
      "metadata": {
        "id": "QZ9efU6BH-iO",
        "outputId": "4623ddea-c95f-47fc-c40b-faeb44a63a6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Lionel Messi è nato il 24 giugno 1987 in Argentina. Messi si è trasferito in Spagna all'età di 13 anni per unirsi al Barcelona. Ha debuttato con il Barcelona all'età di 17 anni nel 2004 e ha avuto una carriera straordinaria sia con il club che con la nazionale argentina.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangChain & Vector Stores (Pinecone)\n"
      ],
      "metadata": {
        "id": "rqrGIAlXJT1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q pinecone-client"
      ],
      "metadata": {
        "id": "zfQX-DKAITFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50bf9aee-6063-4f60-8f39-7d3ddcf85ca9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/215.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/215.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/215.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m215.0/215.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.9/215.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muO57gMQJfdG",
        "outputId": "cd6f1f8e-40e1-4f7c-9f43-20bc458efbf7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pinecone-client\n",
            "Version: 3.2.2\n",
            "Summary: Pinecone client and SDK\n",
            "Home-page: https://www.pinecone.io\n",
            "Author: Pinecone Systems, Inc.\n",
            "Author-email: support@pinecone.io\n",
            "License: Apache-2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: certifi, tqdm, typing-extensions, urllib3\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "PINECONE_API_KEY = getpass('Enter the secret value: ')\n",
        "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSvavSQ4JiNu",
        "outputId": "83f931bf-51f1-4f3b-89b5-c230298b76b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the secret value: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone()\n",
        "pc.list_indexes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm294fvVOVJD",
        "outputId": "6f9e1aa9-1b64-448e-f62e-cb572a802931"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'indexes': [{'dimension': 3072,\n",
              "              'host': 'langchain-3tf20dg.svc.aped-4627-b74a.pinecone.io',\n",
              "              'metric': 'cosine',\n",
              "              'name': 'langchain',\n",
              "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
              "              'status': {'ready': True, 'state': 'Ready'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = 'langchain'\n",
        "pc.describe_index(index_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6tItCpPOoxD",
        "outputId": "fd4d45b3-f34d-4dd1-a85f-4a4f748cd1db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 3072,\n",
              " 'host': 'langchain-3tf20dg.svc.aped-4627-b74a.pinecone.io',\n",
              " 'metric': 'cosine',\n",
              " 'name': 'langchain',\n",
              " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
              " 'status': {'ready': True, 'state': 'Ready'}}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with vectors"
      ],
      "metadata": {
        "id": "wcKIutKyQXeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "vectors = [[random.random() for _ in range(3072)] for v in range(5)]\n",
        "ids = list('abcde')\n",
        "\n",
        "index_name = 'langchain'\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "index.upsert(vectors=zip(ids, vectors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpVxTY-qPh5v",
        "outputId": "6d4af74a-e896-4a8a-8441-fa1e3b04a638"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'upserted_count': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update vector\n",
        "index.upsert(vectors=[('c', [0.5] * 3072)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0qf50dkQmsf",
        "outputId": "db58f098-4eeb-4579-edd4-48560bfc154a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'upserted_count': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.fetch(ids=['c', 'd'])"
      ],
      "metadata": {
        "id": "EJA63hkERLBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oeCrqokYRWa7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}