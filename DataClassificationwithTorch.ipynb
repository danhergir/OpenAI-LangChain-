{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "El Proyecto PyTorch contiene librerías para diferentes tipos de datos y fines.\n",
        "\n",
        "* `torchaudio`\n",
        "* `torchvision`\n",
        "* `TorchElastic`\n",
        "* `TorchServe`"
      ],
      "metadata": {
        "id": "6xMPPzrjus37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a utilizar `torchtext` para clasificación de texto. El paquete `torchtext` consta de utilidades de procesamiento de datos y conjuntos de datos populares para lenguaje natural.\n",
        "\n",
        "Sin embargo, no dudes en probar otras de las librerías disponibles en PyTorch. ¡`torchvision` es particularmente utilizado por aplicaciones que trabajan con imágenes!"
      ],
      "metadata": {
        "id": "Edfy_16KwDse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importando librerías y dataset"
      ],
      "metadata": {
        "id": "iMU-JipBtNZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install portalocker>=2.0.0\n",
        "!pip install torchtext --upgrade"
      ],
      "metadata": {
        "id": "G5Ms82uBZmTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9XsrhAbZqJR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc82dec2-80a1-4d39-8f6c-7289551752d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.15.1+cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.datasets import DBpedia\n",
        "\n",
        "# Comprobar la versión\n",
        "torchtext.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Procesando el dataset y creando un vocabulario"
      ],
      "metadata": {
        "id": "pk7nYHCpmD6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importa las bibliotecas `torch` y `torchtext`. Utiliza `torchtext` para cargar el conjunto de datos DBpedia.\n",
        "\n",
        "Luego, utiliza la función `iter` para crear un objeto de iteración para el conjunto de datos de entrenamiento. Finalmente, el código imprime la versión de la biblioteca `torchtext` utilizada."
      ],
      "metadata": {
        "id": "qILmEFSzN7XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = iter(DBpedia(split=\"train\"))"
      ],
      "metadata": {
        "id": "roB407LAU4mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlY5TiJvnnL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9198551b-b96c-4e65-a8df-38496d20aa4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,\n",
              " 'E. D. Abbott Ltd  Abbott of Farnham E D Abbott Limited was a British coachbuilding business based in Farnham Surrey trading under that name from 1929. A major part of their output was under sub-contract to motor vehicle manufacturers. Their business closed in 1972.')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "next(train_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construiremos un vocabulario con el conjunto de datos implementando la función incorporada `build_vocab_from_iterator`que acepta el iterador que produce una lista o un iterador de tokens.\n",
        "\n",
        "Usamos `torchtext` para construir un vocabulario a partir de un conjunto de datos del DBpedia en inglés.\n",
        "\n",
        "En primer lugar, importa la función `get_tokenizer` de la biblioteca `torchtext` para obtener un tokenizador predefinido para el idioma inglés. Luego, define un iterador de datos para el conjunto de datos de entrenamiento de DBpedia.\n",
        "\n",
        "A continuación, se define una función `yield_tokens` que utiliza el tokenizador para dividir el texto en tokens y devolverlos uno a uno. Esta función se utiliza como entrada para la función `build_vocab_from_iterator`, que construye un vocabulario a partir de los tokens devueltos por la función `yield_tokens`. La función `build_vocab_from_iterator` también toma una lista de tokens especiales, que se utilizarán para representar palabras fuera del vocabulario.\n",
        "\n",
        "En resumen, este fragmento de código construye un vocabulario a partir de un conjunto de datos de entrenamiento y lo prepara para su uso en modelos de aprendizaje automático que utilizan PyTorch.\n",
        "\n"
      ],
      "metadata": {
        "id": "9L1JZNj4wXu6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzSZNEbakkut"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "tokenizador = get_tokenizer(\"basic_english\")\n",
        "train_iter = DBpedia(split=\"train\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "  for _, texto in data_iter:\n",
        "    yield tokenizador(texto)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuestro vocabulario transforma la lista de tokens en números enteros."
      ],
      "metadata": {
        "id": "ICy2-WqrxR1S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51YhJeT3n30n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86972adb-4679-4028-d67f-6e6d676960e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7296, 1506, 47, 578, 2323, 187, 2409, 5, 0, 1078]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "vocab(tokenizador(\"Hello how are you? I am a platzi student\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos dos funciones lambda, `text_pipeline` y `label_pipeline`, que se utilizan para procesar los datos de entrada en un formato que se puede utilizar para entrenar y evaluar modelos.\n",
        "\n",
        "La primera función, `text_pipeline`, toma una cadena de texto como entrada y la procesa utilizando el tokenizador y el vocabulario que definimos. Recuerda que el tokenizador divide el texto en tokens (palabras o subpalabras), mientras que el vocabulario mapea cada token a un índice entero único. La función devuelve una lista de índices enteros que representan los tokens en el texto.\n",
        "\n",
        "La segunda función, `label_pipeline`, toma una etiqueta como entrada y la convierte en un número entero. En este caso, la etiqueta se resta en `1` para ajustarla a un rango de índice de `0` a `n-1`, donde `n` es el número de clases en el problema.\n"
      ],
      "metadata": {
        "id": "t4zd0buNx3QU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tp-PHphn522"
      },
      "outputs": [],
      "source": [
        "texto_pipeline = lambda x: vocab(tokenizador(x))\n",
        "label_pipeline = lambda x: int(x) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL_T7yz6n8al",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f045cad7-4ec2-4418-bf9b-eda67d64cf99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7296, 187, 2409, 5688]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "texto_pipeline(\"Hello I am Omar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EhktKnRn9tq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064ba5be-79e5-46c8-91d8-a137d7573dc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "label_pipeline(\"1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Creamos una función llamada `collate_batch` para procesar un lote de datos. La entrada batch es una lista de tuplas, donde cada tupla contiene una etiqueta y su correspondiente texto.\n",
        "\n",
        "* Se inicializan tres listas: `label_list`, `text_list` y `offsets`. Offsets almacena el índice de inicio de cada secuencia de texto en el tensor concatenado de secuencias de texto. Ayuda a realizar un seguimiento de los límites de las secuencias de texto individuales dentro del tensor concatenado. Comienza con un valor 0, que representa el índice de inicio de la primera secuencia de texto.\n",
        "\n",
        "* La función recorre cada punto de datos en el lote. Para cada punto de datos, procesa la etiqueta utilizando `label_pipeline(_label)` y agrega el resultado a `label_list`. Procesa el texto utilizando `texto_pipeline(_text)` y lo convierte en un tensor de tipo torch.`int64`. El texto procesado se agrega a `text_list` y su longitud `(size(0))` se agrega a offsets.\n",
        "\n",
        "* El último elemento en la lista offsets se elimina mediante el corte `offsets[:-1]`. Luego, la función `cumsum` calcula la suma acumulativa de los elementos en la lista offsets a lo largo de la dimensión 0.\n",
        "\n",
        "* La `text_list` se concatena en un único tensor 1D utilizando `torch.cat(text_list)`.\n",
        "\n",
        "* Los tensores `label_list`, `text_list` y `offsets` se convierten al dispositivo especificado (ya sea GPU o CPU)."
      ],
      "metadata": {
        "id": "kT1kUQ-HydvN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXM1uoT8n_y0"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def collate_batch(batch):\n",
        "  label_list = []\n",
        "  text_list = []\n",
        "  offsets = [0]\n",
        "\n",
        "  for (_label, _text) in batch:\n",
        "    label_list.append(label_pipeline(_label))\n",
        "    processed_text = torch.tensor(texto_pipeline(_text), dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "    offsets.append(processed_text.size(0))\n",
        "\n",
        "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "  text_list = torch.cat(text_list)\n",
        "  return label_list.to(device), text_list.to(device), offsets.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un `DataLoader` maneja el proceso de iteración a través de un conjunto de datos en mini lotes. El DataLoader es importante porque ayuda a administrar de manera eficiente la memoria, mezclar los datos y paralelizar fácilmente la carga de datos."
      ],
      "metadata": {
        "id": "q1lRI55b2b4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_iter = DBpedia(split=\"train\")\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "46kfH6rt2ffj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDyzyJy3Quwx",
        "outputId": "f025faff-e2b0-4882-e785-913aff9053c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f9c0ad4b850>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Creación de modelo de clasificación y sus capas"
      ],
      "metadata": {
        "id": "40Zxp4wbmVce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos `ModeloClasificacionTexto`, una clase de red neuronal que implementa una arquitectura simple pero efectiva para la clasificación de texto, utilizando capas de embedding, normalización por lotes y fully connected.\n",
        "\n",
        "* `__init__(self, vocab_size, embed_dim, num_class)`: Este método inicializa el modelo con tres argumentos: el tamaño del vocabulario (vocab_size), la dimensión de incrustación (embed_dim) y el número de clases (num_class).\n",
        "\n",
        "* `self.embedding`: La capa de incrustación (nn.EmbeddingBag) convierte cada palabra del texto en un vector de dimensión embed_dim. La incrustación se realiza de forma eficiente en lotes para las secuencias de texto en la entrada.\n",
        "\n",
        "* `self.bn1`: La capa de normalización por lotes (nn.BatchNorm1d) mejora la estabilidad y la velocidad de entrenamiento del modelo, normalizando las características de entrada a lo largo de la dimensión especificada (en este caso, embed_dim).\n",
        "\n",
        "* `self.fc`: La capa completamente conectada (nn.Linear) realiza la proyección de las características de incrustación normalizadas y activadas en un espacio de dimensión igual al número de clases (num_class). Esta capa produce las probabilidades de clase para la clasificación."
      ],
      "metadata": {
        "id": "sF_m53Ab0oiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModeloClasificacionTexto(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, num_class):\n",
        "    super(ModeloClasificacionTexto, self).__init__()\n",
        "\n",
        "        # Capa de incrustación (embedding)\n",
        "    self.embedding = nn.EmbeddingBag(vocab_size, embed_dim)\n",
        "\n",
        "        # Capa de normalización por lotes (batch normalization)\n",
        "    self.bn1 = nn.BatchNorm1d(embed_dim)\n",
        "\n",
        "        # Capa completamente conectada (fully connected)\n",
        "    self.fc = nn.Linear(embed_dim, num_class)\n",
        "\n",
        "  def forward(self, text, offsets):\n",
        "        # Incrustar el texto (embed the text)\n",
        "    embedded = self.embedding(text, offsets)\n",
        "\n",
        "        # Aplicar la normalización por lotes (apply batch normalization)\n",
        "    embedded_norm = self.bn1(embedded)\n",
        "\n",
        "        # Aplicar la función de activación ReLU (apply the ReLU activation function)\n",
        "    embedded_activated = F.relu(embedded_norm)\n",
        "\n",
        "        # Devolver las probabilidades de clase (output the class probabilities)\n",
        "    return self.fc(embedded_activated)\n"
      ],
      "metadata": {
        "id": "35MlAHmY_IVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construimos un modelo con una dimensión de embedding de 100."
      ],
      "metadata": {
        "id": "YZFru1zL1soL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2KLlcb8oE7s"
      },
      "outputs": [],
      "source": [
        "train_iter = DBpedia(split=\"train\")\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "embedding_size = 100\n",
        "\n",
        "modelo = ModeloClasificacionTexto(vocab_size=vocab_size, embed_dim=embedding_size, num_class=num_class).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5o7sivgXtkJ",
        "outputId": "3dd97045-4151-4112-b24e-c304c6b0b6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "802998"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# arquitectura\n",
        "# print(modelo)\n",
        "\n",
        "# Número de parámetros entrenables en nuestro modelo\n",
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"El modelo tiene {count_parameters(modelo):,} parámetros entrenables\")"
      ],
      "metadata": {
        "id": "6Yf7_o-h83XL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f339047-614c-4c7e-96c1-92442c920e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El modelo tiene 80,301,414 parámetros entrenables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Funciones para entrenamiento y evaluación del modelo"
      ],
      "metadata": {
        "id": "u9erCn5fmiU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, definimos las funciones para entrenar el modelo y evaluar los resultados.\n",
        "\n",
        "Utilizamos `torch.nn.utils.clip_grad_norm_` para limitar el valor máximo de la norma del gradiente durante el entrenamiento de una red neuronal. En otras palabras, se asegura de que los gradientes no sean demasiado grandes y, por lo tanto, evita que la red neuronal se vuelva inestable durante el entrenamiento.\n",
        "\n",
        "El primer argumento, `modelo.parameters()`, se refiere a los parámetros del modelo que se están entrenando. El segundo argumento, \"0.1\", es el valor máximo permitido para la norma del gradiente."
      ],
      "metadata": {
        "id": "Fx_CnCPv3ZC4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgXcW2GroHJ1"
      },
      "outputs": [],
      "source": [
        "def entrena(dataloader):\n",
        "    # Colocar el modelo en formato de entrenamiento\n",
        "    modelo.train()\n",
        "\n",
        "    # Inicializa accuracy, count y loss para cada epoch\n",
        "    epoch_acc = 0\n",
        "    epoch_loss = 0\n",
        "    total_count = 0\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        # reestablece los gradientes después de cada batch\n",
        "        optimizer.zero_grad()\n",
        "        # Obten predicciones del modelo\n",
        "        prediccion = modelo(text, offsets)\n",
        "\n",
        "        # Obten la pérdida\n",
        "        loss = criterio(prediccion, label)\n",
        "\n",
        "        # backpropage la pérdida y calcular los gradientes\n",
        "        loss.backward()\n",
        "\n",
        "        # Obten la accuracy\n",
        "        acc = (prediccion.argmax(1) == label).sum()\n",
        "\n",
        "        # Evita que los gradientes sean demasiado grandes\n",
        "        torch.nn.utils.clip_grad_norm_(modelo.parameters(), 0.1)\n",
        "\n",
        "        # Actualiza los pesos\n",
        "        optimizer.step()\n",
        "\n",
        "        # Llevamos el conteo de la pérdida y el accuracy para esta epoch\n",
        "        epoch_acc += acc.item()\n",
        "        epoch_loss += loss.item()\n",
        "        total_count += label.size(0)\n",
        "\n",
        "        if idx % 500 == 0 and idx > 0:\n",
        "          print(f\" epoca {epoch} | {idx}/{len(dataloader)} batches | perdida {epoch_loss/total_count} | accuracy {epoch_acc/total_count}\")\n",
        "\n",
        "    return epoch_acc/total_count, epoch_loss/total_count\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evalua(dataloader):\n",
        "  modelo.eval()\n",
        "  epoch_acc = 0\n",
        "  total_count = 0\n",
        "  epoch_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            # Obtenemos la la etiqueta predecida\n",
        "      prediccion = modelo(text, offsets)\n",
        "\n",
        "            # Obtenemos pérdida y accuracy\n",
        "      loss = criterio(prediccion, label)\n",
        "      acc = (prediccion.argmax(1) == label).sum()\n",
        "\n",
        "            # Llevamos el conteo de la pérdida y el accuracy para esta epoch\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "      total_count += label.size(0)\n",
        "\n",
        "  return epoch_acc/total_count, epoch_loss/total_count\n"
      ],
      "metadata": {
        "id": "p7CrDdiBCfGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Preparando el entrenamiento: split de datos, pérdida y optimización"
      ],
      "metadata": {
        "id": "jVPSvNQMmsP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos el conjunto de datos de entrenamiento en conjuntos de entrenamiento válidos con una proporción de división de 0.95 (entrenamiento) y 0.5 (válido) utilizando la función `torch.utils.data.dataset.random_split`\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "CUx3ZTzN3-oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros\n",
        "\n",
        "EPOCHS = 4 # epochs\n",
        "TASA_APRENDIZAJE = 0.2  # tasa de aprendizaje\n",
        "BATCH_TAMANO = 64 # tamaño de los batches"
      ],
      "metadata": {
        "id": "rE9Bq2O-XNq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explora las otras funciones de pérdida disponibles en PyTorch. Puedes encontrarlas todas aquí: https://pytorch.org/docs/stable/nn.html#loss-functions.\n",
        "\n",
        "La función de pérdida es la que mide qué tan buenas son las predicciones de nuestro modelo en comparación con las etiquetas reales. PyTorch ofrece una amplia gama de funciones de pérdida que podemos utilizar para entrenar nuestros modelos en diferentes tipos de problemas, como regresión, clasificación y modelado de secuencia a secuencia.\n",
        "\n",
        "Al profundizar en estas otras funciones de pérdida, podemos ampliar nuestro conocimiento de machine learning. Lo mismo aplica para los optimizadores. PyTorch proporciona una variedad de algoritmos de optimización: https://pytorch.org/docs/stable/optim.html#algorithms.\n",
        "\n",
        "Dedica tiempo a explorar la documentación de PyTorch sobre funciones de pérdida y optimizadores. Experimenta con diferentes funciones en tus proyectos."
      ],
      "metadata": {
        "id": "Gu-TQyvd5KMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pérdida, optimizador\n",
        "criterio = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr= TASA_APRENDIZAJE)"
      ],
      "metadata": {
        "id": "DtM-yw0QX5ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos el conjunto de datos en tres partes: entrenamiento, validación y prueba.\n",
        "\n",
        "Primero, importamos la función `random_split` de la clase Dataset y la función `to_map_style_dataset` de `torchtext.data.functional`. Luego, cargamos el conjunto de datos `DBpedia` usando el método `DBpedia()`. A continuación, convertimos el conjunto de datos en un formato que pueda ser utilizado por el `DataLoader` de PyTorch utilizando la función `to_map_style_dataset`.\n",
        "\n",
        "Luego, definimos la proporción de datos que utilizaremos para entrenar nuestro modelo (el 95%) y el porcentaje que utilizaremos para validar nuestro modelo (el 5%). Utilizamos la función `random_split` para dividir el conjunto de datos de entrenamiento en entrenamiento y validación.\n",
        "\n",
        "Finalmente, creamos tres DataLoaders para cada parte del conjunto de datos: uno para el entrenamiento, uno para la validación y otro para la prueba. Utilizamos el argumento `batch_size` para definir el tamaño de los lotes de datos que se utilizarán en el entrenamiento y la prueba. El argumento `collate_fn` especifica cómo se deben unir las muestras de datos para formar un lote.\n"
      ],
      "metadata": {
        "id": "vas4IcYu7qV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "# Obten el trainset y testset\n",
        "train_iter, test_iter = DBpedia()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "\n",
        "# Entrenamos el modelo con el 95% de los datos del trainset\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "\n",
        "# Creamos un dataset de validación con el 5% del trainset\n",
        "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset)-num_train])\n",
        "\n",
        "# Creamos dataloaders listos para ingresar a nuestro modelo\n",
        "train_dataloader = DataLoader(split_train_, batch_size=BATCH_TAMANO, shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_TAMANO, shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_TAMANO, shuffle=True, collate_fn=collate_batch)\n"
      ],
      "metadata": {
        "id": "Er7axMVCZw5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxJHo0z51lcO",
        "outputId": "87ddbcba-7a05-401f-eb4f-bf437eeab625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.data.functional.to_map_style_dataset.<locals>._MapStyleDataset at 0x7f9c00617910>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Entrenamiento y evaluación del modelo"
      ],
      "metadata": {
        "id": "gliGM0f8m41V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a entrenar y evaluar nuestro modelo. En primer lugar, se define la variable `mejor_loss_validacion` y se inicializa con un valor infinito positivo. Esta variable se utiliza para realizar un seguimiento de la mejor pérdida de validación durante el entrenamiento.\n",
        "\n",
        "Luego, se realiza un `for` a través de las épocas. Dentro de cada época, se realiza el entrenamiento y la validación del modelo utilizando los conjuntos de datos de entrenamiento y validación respectivamente.\n",
        "\n",
        "En otras palabras, si la pérdida de validación actual es menor que la mejor pérdida de validación anterior, se guarda el estado actual del modelo en el archivo `pesos_guardados.pt`.\n"
      ],
      "metadata": {
        "id": "EL8OJQFp8IfR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qls71GpHoLfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f3195a-8b25-4d1b-d1ff-8d020796e0c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoca 1 | 500/8313 batches | perdida 0.032902928325765864 | accuracy 0.405750998003992\n",
            " epoca 1 | 1000/8313 batches | perdida 0.028361984419745283 | accuracy 0.4977990759240759\n",
            " epoca 1 | 1500/8313 batches | perdida 0.02571954714105794 | accuracy 0.538994836775483\n",
            " epoca 1 | 2000/8313 batches | perdida 0.023957685622359174 | accuracy 0.5656546726636682\n",
            " epoca 1 | 2500/8313 batches | perdida 0.02272837197460958 | accuracy 0.5840976109556177\n",
            " epoca 1 | 3000/8313 batches | perdida 0.021802839020224302 | accuracy 0.5981860213262246\n",
            " epoca 1 | 3500/8313 batches | perdida 0.0210751858748702 | accuracy 0.6086609183090546\n",
            " epoca 1 | 4000/8313 batches | perdida 0.020481141552960342 | accuracy 0.6171113471632091\n",
            " epoca 1 | 4500/8313 batches | perdida 0.019971808727968866 | accuracy 0.6246320262163964\n",
            " epoca 1 | 5000/8313 batches | perdida 0.019515828055550674 | accuracy 0.6314893271345731\n",
            " epoca 1 | 5500/8313 batches | perdida 0.019135302032749178 | accuracy 0.6372818578440284\n",
            " epoca 1 | 6000/8313 batches | perdida 0.018799089082175147 | accuracy 0.642418971838027\n",
            " epoca 1 | 6500/8313 batches | perdida 0.018489704182558592 | accuracy 0.6473475234579296\n",
            " epoca 1 | 7000/8313 batches | perdida 0.01822629640786912 | accuracy 0.651377928153121\n",
            " epoca 1 | 7500/8313 batches | perdida 0.017981029437315287 | accuracy 0.6552168044260765\n",
            " epoca 1 | 8000/8313 batches | perdida 0.01775996236626695 | accuracy 0.6588746719160105\n",
            " epoca 2 | 500/8313 batches | perdida 0.014083711647924905 | accuracy 0.7180950598802395\n",
            " epoca 2 | 1000/8313 batches | perdida 0.014000869499376187 | accuracy 0.7208884865134865\n",
            " epoca 2 | 1500/8313 batches | perdida 0.013889413142389432 | accuracy 0.7231324950033311\n",
            " epoca 2 | 2000/8313 batches | perdida 0.013815248957316185 | accuracy 0.7242706771614192\n",
            " epoca 2 | 2500/8313 batches | perdida 0.013752546153593212 | accuracy 0.725203668532587\n",
            " epoca 2 | 3000/8313 batches | perdida 0.013711620206761236 | accuracy 0.7261954348550483\n",
            " epoca 2 | 3500/8313 batches | perdida 0.013642008830408808 | accuracy 0.7276581690945444\n",
            " epoca 2 | 4000/8313 batches | perdida 0.013604809632150085 | accuracy 0.7281656148462884\n",
            " epoca 2 | 4500/8313 batches | perdida 0.013532305847798796 | accuracy 0.7296815985336592\n",
            " epoca 2 | 5000/8313 batches | perdida 0.013484614939979912 | accuracy 0.7305726354729054\n",
            " epoca 2 | 5500/8313 batches | perdida 0.013415142989953936 | accuracy 0.7320487184148337\n",
            " epoca 2 | 6000/8313 batches | perdida 0.01335677230551248 | accuracy 0.7332684135977338\n",
            " epoca 2 | 6500/8313 batches | perdida 0.013292152955474862 | accuracy 0.7344374903860944\n",
            " epoca 2 | 7000/8313 batches | perdida 0.013232997984573119 | accuracy 0.7354864483645194\n",
            " epoca 2 | 7500/8313 batches | perdida 0.01317714873946922 | accuracy 0.73651638114918\n",
            " epoca 2 | 8000/8313 batches | perdida 0.01313835280506112 | accuracy 0.7374136826646669\n",
            " epoca 3 | 500/8313 batches | perdida 0.012192782009961064 | accuracy 0.7526197604790419\n",
            " epoca 3 | 1000/8313 batches | perdida 0.012132194060199596 | accuracy 0.7558379120879121\n",
            " epoca 3 | 1500/8313 batches | perdida 0.01203126286644784 | accuracy 0.7583590106595602\n",
            " epoca 3 | 2000/8313 batches | perdida 0.012007763746358837 | accuracy 0.7582927286356822\n",
            " epoca 3 | 2500/8313 batches | perdida 0.011959394012003993 | accuracy 0.7592463014794082\n",
            " epoca 3 | 3000/8313 batches | perdida 0.011918501329962977 | accuracy 0.7600383205598134\n",
            " epoca 3 | 3500/8313 batches | perdida 0.01186667972701072 | accuracy 0.761260175664096\n",
            " epoca 3 | 4000/8313 batches | perdida 0.011823829855970988 | accuracy 0.762215696075981\n",
            " epoca 3 | 4500/8313 batches | perdida 0.01178663569777522 | accuracy 0.7629033825816485\n",
            " epoca 3 | 5000/8313 batches | perdida 0.011736964828516694 | accuracy 0.7639222155568887\n",
            " epoca 3 | 5500/8313 batches | perdida 0.01169897682884892 | accuracy 0.76457689510998\n",
            " epoca 3 | 6000/8313 batches | perdida 0.011664214617793257 | accuracy 0.7653307782036327\n",
            " epoca 3 | 6500/8313 batches | perdida 0.011628252467639953 | accuracy 0.7659038032610368\n",
            " epoca 3 | 7000/8313 batches | perdida 0.01159425332820089 | accuracy 0.7665735252106842\n",
            " epoca 3 | 7500/8313 batches | perdida 0.01156637931680621 | accuracy 0.7672227036395147\n",
            " epoca 3 | 8000/8313 batches | perdida 0.011521178889887424 | accuracy 0.7681832739657543\n",
            " epoca 4 | 500/8313 batches | perdida 0.010729499860200102 | accuracy 0.7861152694610778\n",
            " epoca 4 | 1000/8313 batches | perdida 0.010807835382523832 | accuracy 0.7829982517482518\n",
            " epoca 4 | 1500/8313 batches | perdida 0.010810631460111233 | accuracy 0.784029397068621\n",
            " epoca 4 | 2000/8313 batches | perdida 0.010765614968001738 | accuracy 0.7847872938530734\n",
            " epoca 4 | 2500/8313 batches | perdida 0.01073752139925492 | accuracy 0.7849985005997601\n",
            " epoca 4 | 3000/8313 batches | perdida 0.010696314561783757 | accuracy 0.7858942852382539\n",
            " epoca 4 | 3500/8313 batches | perdida 0.010680161579265995 | accuracy 0.7859540131391031\n",
            " epoca 4 | 4000/8313 batches | perdida 0.01065057843603041 | accuracy 0.7866392776805798\n",
            " epoca 4 | 4500/8313 batches | perdida 0.010619472710260949 | accuracy 0.7873666962897135\n",
            " epoca 4 | 5000/8313 batches | perdida 0.010580762117530148 | accuracy 0.7879361627674465\n",
            " epoca 4 | 5500/8313 batches | perdida 0.01054351840812765 | accuracy 0.7886009361934194\n",
            " epoca 4 | 6000/8313 batches | perdida 0.010515166919328021 | accuracy 0.7891575362439593\n",
            " epoca 4 | 6500/8313 batches | perdida 0.010500038169197472 | accuracy 0.7891430164590063\n",
            " epoca 4 | 7000/8313 batches | perdida 0.010487635150519072 | accuracy 0.789373839451507\n",
            " epoca 4 | 7500/8313 batches | perdida 0.010462283990638291 | accuracy 0.7898134415411279\n",
            " epoca 4 | 8000/8313 batches | perdida 0.01044318658620312 | accuracy 0.7902820741157355\n"
          ]
        }
      ],
      "source": [
        "# Obten la mejor pérdida\n",
        "major_loss_validation = float('inf')\n",
        "\n",
        "# Entrenamos\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # Entrenamiento\n",
        "    entrenamiento_acc, entrenamiento_loss = entrena(train_dataloader)\n",
        "\n",
        "    # Validación\n",
        "    validacion_acc, validacion_loss = evalua(valid_dataloader)\n",
        "\n",
        "    # Guarda el mejor modelo\n",
        "    if validacion_loss < major_loss_validation:\n",
        "      best_valid_loss = validacion_loss\n",
        "      torch.save(modelo.state_dict(), \"mejores_guardados.pt\")\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluamos el modelo en el test dataset"
      ],
      "metadata": {
        "id": "Us9eYmrT4YFq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-rMpCWWoObX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89b8d283-1f82-4e8f-a5c9-ca532196f49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy del test dataset -> 0.8018857142857143\n",
            "Pérdida del test dataset -> 0.00986104992713247\n"
          ]
        }
      ],
      "source": [
        "test_acc, test_loss = evalua(test_dataloader)\n",
        "\n",
        "print(f'Accuracy del test dataset -> {test_acc}')\n",
        "print(f'Pérdida del test dataset -> {test_loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Inferencia"
      ],
      "metadata": {
        "id": "3WE1DDsfm-1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probemos con un ejemplo. Probemos con dos ejemplos de textos en inglés. Usaremos `torch.compile()` para la acelerar la inferencia del modelo. Le damos el argumento `mode=\"reduce-overhead\"` que hace referencia a reducir el overhead computacional de nuestro modelo, es decir, reducir recursos computacionales como el uso del GPU y reducir el tiempo necesario para correr la inferencia o, en otros casos, entrenar el modelo.\n",
        "\n",
        "`reduce-overhead` permite que nuestro código se ejecute de manera más eficiente. Sin embargo, esta optimización puede tener el costo de una pequeña cantidad de memoria adicional. Es el modo recomendado para modelos pequeños como el nuestro para clasificación.\n",
        "\n",
        "El modo `max-autotune` compila el código durante más tiempo, tratando de optimizar el código tanto como sea posible para lograr la mayor velocidad de ejecución. Este modo puede implicar explorar diferentes estrategias de optimización y encontrar la mejor, lo que puede dar como resultado tiempos de compilación más largos pero un mejor rendimiento durante la ejecución.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5ee1sonK5Dns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98utU4rmoRQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c77748-fb6f-4380-9533-a31783f55989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El ejemplo 1 es de categoría Village\n"
          ]
        }
      ],
      "source": [
        "DBpedia_label = {1: 'Company',\n",
        "                2: 'EducationalInstitution',\n",
        "                3: 'Artist',\n",
        "                4: 'Athlete',\n",
        "                5: 'OfficeHolder',\n",
        "                6: 'MeanOfTransportation',\n",
        "                7: 'Building',\n",
        "                8: 'NaturalPlace',\n",
        "                9: 'Village',\n",
        "                10: 'Animal',\n",
        "                11: 'Plant',\n",
        "                12: 'Album',\n",
        "                13: 'Film',\n",
        "                14: 'WrittenWork'}\n",
        "\n",
        "def predict(text, texto_pipeline):\n",
        "  with torch.no_grad():\n",
        "    text = torch.tensor(texto_pipeline(text))\n",
        "    opt_mod = torch.compile(model, mode=\"reduce-overhead\")\n",
        "    output = opt_mod(text, torch.tensor([0]))\n",
        "    return output.argmax(1).item() + 1\n",
        "\n",
        "\n",
        "ejemplo_1 = \"Nithari is a village in the western part of the state of Uttar Pradesh India bordering on New Delhi. Nithari forms part of the New Okhla Industrial Development Authority's planned industrial city Noida falling in Sector 31. Nithari made international news headlines in December 2006 when the skeletons of a number of apparently murdered women and children were unearthed in the village.\"\n",
        "\n",
        "\n",
        "model = modelo.to(\"cpu\")\n",
        "\n",
        "\n",
        "print(f\"El ejemplo 1 es de categoría {DBpedia_label[predict(ejemplo_1, texto_pipeline)]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Almacenamiento y carga del modelo"
      ],
      "metadata": {
        "id": "0ILMPS41nBWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método `state_dict()` se utiliza para devolver el diccionario del estado del modelo. Este diccionario contiene todos los parámetros entrenables del modelo. Como pesos y sesgos en forma de tensores de PyTorch.\n",
        "\n",
        "Es útil para una variedad de tareas, como guardar y cargar modelos o transferir los parámetros aprendidos de un modelo a otro. Permite manipular fácilmente el estado del modelo como un diccionario de parámetros con nombres, sin tener que acceder a ellos directamente.\n",
        "\n",
        "Por ejemplo, si queremos guardar nuestro modelo en el disco de memoria, podemos utilizarlo para obtener un diccionario de los parámetros del modelo y luego guardar ese diccionario utilizando el módulo `pickle` de Python. Luego, cuando queramos cargar el modelo nuevamente, podemos utilizar el método `load_state_dict()` para cargar el diccionario guardado en una nueva instancia del modelo."
      ],
      "metadata": {
        "id": "b4lhw1sIEBuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = model.state_dict()\n",
        "optimizer_state_dict = optimizer.state_dict()\n",
        "\n",
        "checkpoint = {\n",
        "    \"model_state_dict\" :  model_state_dict,\n",
        "    \"optimizer_state_dict\" : optimizer_state_dict,\n",
        "    \"epoch\" : epoch,\n",
        "    \"loss\" : entrenamiento_loss,\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, \"model_checkpoint.pth\")"
      ],
      "metadata": {
        "id": "Hz73sOEfYqec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subimos el modelo al Hub de Hugging Face para que otros miembros de la comunidad tengan acceso a él y también tengamos una copia en la nube."
      ],
      "metadata": {
        "id": "NswONO0lZTBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "HdRy2iFrFUrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BxPgoPcFqHQ",
        "outputId": "66b3d3b6-3c87-4812-edd9-d9ccb7c8799b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos el repositorio donde guardaremos nuestro modelo en el Hub de Hugging Face."
      ],
      "metadata": {
        "id": "FCsO5zI8ZWvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "api.create_repo(repo_id=\"platzi/clasificacion-DBpedia-omar-espejel\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "MAXfKEDpHEx2",
        "outputId": "dbebe2d8-c004-4a63-987a-a592f07e62ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RepoUrl('https://huggingface.co/platzi/clasificacion-DBpedia-omar-espejel', endpoint='https://huggingface.co', repo_type='model', repo_id='platzi/clasificacion-DBpedia-omar-espejel')"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subimos nuestro checkpoint."
      ],
      "metadata": {
        "id": "H0GKxQDiZbnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-krg_53IC16",
        "outputId": "30a9927a-2c31-40bb-cbda-d6389906e09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'=2.0.0'   mejores_guardados.pt   model_checkpoint.pth\t sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api.upload_file(\n",
        "    path_or_fileobj=\"./model_checkpoint.pth\",\n",
        "    path_in_repo=\"model_checkpoint.pth\",\n",
        "    repo_id=\"platzi/clasificacion-DBpedia-omar-espejel\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "e16ccee0890945f499e701b39bf49020",
            "dd4d77d9c08f4cda9a0eca7c52c5b201",
            "069936e7e9c140858f2466cf389c5da3",
            "d8d9cf660ee64bb7afd76c6ef1273282",
            "527327d5635a4ff0bfa7c08eaf884230",
            "81df1d978fd445ac9fe466d4d9fcbabf",
            "213a261665b343169f5e174085b04a7d",
            "656b9cd62da04e2eb6888e1f77458285",
            "b85f17ccdc624bb685939e3ade60a6e6",
            "862e95a108264bca959b66761b77f2be",
            "e2ddb41dc62a4705b8204733e0be3343",
            "5e3faaa864e24ecfb02abc14d5fe50b4",
            "1219400d58d94f67a6d3dfeb82cd5c13",
            "2ef7c510462b4cf3a31efc398f2e5e78",
            "f8b1a9ea410f44dfbd07476dc9fa2fec",
            "b1549f9234bf445381fb2b7a4e2ef76c",
            "99b27625a47a48239915c036bf1be5de",
            "4b78a12b81a24f3ca2aaa935d413218f",
            "d0fe81aeea114b8ab834eb36f69125e8",
            "7e59cc36a6ca4b3895a3c702e6fabdca",
            "0c8c595fd5d543e1bbfafa5fc097ffd9",
            "bb0cf180dcb74282aac2fe1fe076840d"
          ]
        },
        "id": "paKQlFNbZgW7",
        "outputId": "9e90b965-036b-470b-85ad-33c90fff9428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e16ccee0890945f499e701b39bf49020"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_checkpoint.pth:   0%|          | 0.00/321M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e3faaa864e24ecfb02abc14d5fe50b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://huggingface.co/platzi/clasificacion-DBpedia-omar-espejel/blob/main/model_checkpoint.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carguemos el checkpoint en un nuevo directorio llamado `weights`."
      ],
      "metadata": {
        "id": "beSaNZZhZgtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir weights"
      ],
      "metadata": {
        "id": "II9yD1F6Zl4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm weights/model_checkpoint.pth"
      ],
      "metadata": {
        "id": "1VhAtfMLR_wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "hf_hub_download(repo_id=\"platzi/clasificacion-DBpedia-omar-espejel\", filename=\"model_checkpoint.pth\", local_dir=\"weights/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "cd65a81394904e8fa1d80bc1257ea477",
            "4faabae0dcca4fe09280ee46a00dcbfe",
            "3d9699d596054659afab5835f4ac1a27",
            "9fd808d2f9de4ecbb714a21138d62cc6",
            "80e3866c09e741a2b796c438f5856b53",
            "ef94e5a27da74b38936976e5ac545677",
            "c6cd98f12b774ca486f91af662912a74",
            "92c2aed768df4d8b90073f4d7a93d377",
            "9107661b112f468e899f6b68d7fbba96",
            "957c621e71fe48709efd2c645255a48b",
            "d18d65ecd05549d0ab552855ba39a5c5"
          ]
        },
        "id": "ephoHvmaZmAa",
        "outputId": "2a565e92-d211-4690-a635-4425823f7418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model_checkpoint.pth:   0%|          | 0.00/321M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd65a81394904e8fa1d80bc1257ea477"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'weights/model_checkpoint.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meO27R9wJPdL",
        "outputId": "7d4e469b-9f0c-455f-c659-fa762e74b375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_checkpoint.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora carguemos nuestro modelo"
      ],
      "metadata": {
        "id": "0dX7GS5UlYDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"weights/model_checkpoint.pth\")"
      ],
      "metadata": {
        "id": "g7rzc6jNMNsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = DBpedia(split=\"train\")\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "embedding_size = 100\n",
        "\n",
        "modelo_2 = ModeloClasificacionTexto(vocab_size=vocab_size, embed_dim=embedding_size, num_class=num_class)"
      ],
      "metadata": {
        "id": "hgkhVYL6MeZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_2 = torch.optim.SGD(modelo_2.parameters(), lr=0.2)"
      ],
      "metadata": {
        "id": "D4922nWaM_q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_2.load_state_dict(checkpoint[\"model_state_dict\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDnio1aVQplK",
        "outputId": "e7cdccf6-a1b0-41ee-df2a-cc8be9e4295a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_2.load_state_dict(checkpoint[\"optimizer_state_dict\"])"
      ],
      "metadata": {
        "id": "ohMDxH4yQ1Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_2 = checkpoint[\"epoch\"]\n",
        "loss_2 = checkpoint[\"loss\"]"
      ],
      "metadata": {
        "id": "whbpaxOGSf0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ejemplo_2 = \"Axolotls are members of the tiger salamander, or Ambystoma tigrinum, species complex, along with all other Mexican species of Ambystoma.\"\n",
        "\n",
        "model_cpu = modelo_2.to(\"cpu\")\n",
        "\n",
        "DBpedia_label[predict(ejemplo_2, texto_pipeline)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "55rQz-cwTKdR",
        "outputId": "5d6b038b-e0f3-4b2f-bcb6-12c55c462a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Animal'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusión\n",
        "\n",
        "En este módulo aprendimos a utilizar `torchtext` para entrenar un modelo de clasificación con datos reales.\n",
        "\n",
        "1. Empezamos por preprocesar los datos mediante la tokenización y la construcción de un vocabulario.\n",
        "\n",
        "2. Luego creamos un conjunto de datos de PyTorch y lo usamos para entrenar un modelo de clasificación con una arquitectura de red neuronal.\n",
        "\n",
        "3. Probamos el modelo con un conjunto de pruebas\n",
        "\n",
        "4. Luego realizamos inferencia en nuevos datos.\n",
        "\n",
        "5. Finalmente, guardamos nuestro modelo entrenado para que pueda ser utilizado más adelante para otras tareas."
      ],
      "metadata": {
        "id": "He-_-eWWlAn-"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e16ccee0890945f499e701b39bf49020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd4d77d9c08f4cda9a0eca7c52c5b201",
              "IPY_MODEL_069936e7e9c140858f2466cf389c5da3",
              "IPY_MODEL_d8d9cf660ee64bb7afd76c6ef1273282"
            ],
            "layout": "IPY_MODEL_527327d5635a4ff0bfa7c08eaf884230"
          }
        },
        "dd4d77d9c08f4cda9a0eca7c52c5b201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81df1d978fd445ac9fe466d4d9fcbabf",
            "placeholder": "​",
            "style": "IPY_MODEL_213a261665b343169f5e174085b04a7d",
            "value": "Upload 1 LFS files: 100%"
          }
        },
        "069936e7e9c140858f2466cf389c5da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_656b9cd62da04e2eb6888e1f77458285",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b85f17ccdc624bb685939e3ade60a6e6",
            "value": 1
          }
        },
        "d8d9cf660ee64bb7afd76c6ef1273282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_862e95a108264bca959b66761b77f2be",
            "placeholder": "​",
            "style": "IPY_MODEL_e2ddb41dc62a4705b8204733e0be3343",
            "value": " 1/1 [01:16&lt;00:00, 76.83s/it]"
          }
        },
        "527327d5635a4ff0bfa7c08eaf884230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81df1d978fd445ac9fe466d4d9fcbabf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213a261665b343169f5e174085b04a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "656b9cd62da04e2eb6888e1f77458285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85f17ccdc624bb685939e3ade60a6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "862e95a108264bca959b66761b77f2be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ddb41dc62a4705b8204733e0be3343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e3faaa864e24ecfb02abc14d5fe50b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1219400d58d94f67a6d3dfeb82cd5c13",
              "IPY_MODEL_2ef7c510462b4cf3a31efc398f2e5e78",
              "IPY_MODEL_f8b1a9ea410f44dfbd07476dc9fa2fec"
            ],
            "layout": "IPY_MODEL_b1549f9234bf445381fb2b7a4e2ef76c"
          }
        },
        "1219400d58d94f67a6d3dfeb82cd5c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99b27625a47a48239915c036bf1be5de",
            "placeholder": "​",
            "style": "IPY_MODEL_4b78a12b81a24f3ca2aaa935d413218f",
            "value": "model_checkpoint.pth: 100%"
          }
        },
        "2ef7c510462b4cf3a31efc398f2e5e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0fe81aeea114b8ab834eb36f69125e8",
            "max": 321209513,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e59cc36a6ca4b3895a3c702e6fabdca",
            "value": 321209513
          }
        },
        "f8b1a9ea410f44dfbd07476dc9fa2fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c8c595fd5d543e1bbfafa5fc097ffd9",
            "placeholder": "​",
            "style": "IPY_MODEL_bb0cf180dcb74282aac2fe1fe076840d",
            "value": " 321M/321M [01:16&lt;00:00, 2.85MB/s]"
          }
        },
        "b1549f9234bf445381fb2b7a4e2ef76c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99b27625a47a48239915c036bf1be5de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b78a12b81a24f3ca2aaa935d413218f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0fe81aeea114b8ab834eb36f69125e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e59cc36a6ca4b3895a3c702e6fabdca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c8c595fd5d543e1bbfafa5fc097ffd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb0cf180dcb74282aac2fe1fe076840d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd65a81394904e8fa1d80bc1257ea477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4faabae0dcca4fe09280ee46a00dcbfe",
              "IPY_MODEL_3d9699d596054659afab5835f4ac1a27",
              "IPY_MODEL_9fd808d2f9de4ecbb714a21138d62cc6"
            ],
            "layout": "IPY_MODEL_80e3866c09e741a2b796c438f5856b53"
          }
        },
        "4faabae0dcca4fe09280ee46a00dcbfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef94e5a27da74b38936976e5ac545677",
            "placeholder": "​",
            "style": "IPY_MODEL_c6cd98f12b774ca486f91af662912a74",
            "value": "Downloading model_checkpoint.pth: 100%"
          }
        },
        "3d9699d596054659afab5835f4ac1a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92c2aed768df4d8b90073f4d7a93d377",
            "max": 321209513,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9107661b112f468e899f6b68d7fbba96",
            "value": 321209513
          }
        },
        "9fd808d2f9de4ecbb714a21138d62cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_957c621e71fe48709efd2c645255a48b",
            "placeholder": "​",
            "style": "IPY_MODEL_d18d65ecd05549d0ab552855ba39a5c5",
            "value": " 321M/321M [00:18&lt;00:00, 19.7MB/s]"
          }
        },
        "80e3866c09e741a2b796c438f5856b53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef94e5a27da74b38936976e5ac545677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6cd98f12b774ca486f91af662912a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92c2aed768df4d8b90073f4d7a93d377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9107661b112f468e899f6b68d7fbba96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "957c621e71fe48709efd2c645255a48b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d18d65ecd05549d0ab552855ba39a5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}